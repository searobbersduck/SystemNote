
## 官方资料

**这些资料非常重要**

* **[NVIDIA NCCL](https://developer.nvidia.com/nccl)**
  * 官网链接；
* **[Troubleshooting](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/troubleshooting.html#gpu-to-gpu-communication)**
* **[NCCL: High-Speed Inter-GPU Communication for Large-Scale Training](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31880/)**
  * pdf可以下载，很多有用信息；

* **[Massively Scale Your Deep Learning Training with NCCL 2.4](https://developer.nvidia.com/blog/massively-scale-deep-learning-training-nccl-2-4/)**

* **[Doubling all2all Performance with NVIDIA Collective Communication Library 2.12](https://developer.nvidia.com/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/)**
  * 

<br><br>

## Blog

1. [如何理解Nvidia英伟达的Multi-GPU多卡通信框架NCCL？](https://www.zhihu.com/question/63219175)
   * 可以反复看

2. [Pytorch 分布式训练](https://zhuanlan.zhihu.com/p/76638962)
   * 废话连篇，可以简单看一下开头

3. [DISTRIBUTED COMMUNICATION PACKAGE - TORCH.DISTRIBUTED](https://pytorch.org/docs/stable/distributed.html)
   * pytorch官方文档

4. [【研究综述】浅谈GPU通信和PCIe P2P DMA](https://zhuanlan.zhihu.com/p/430101220)

5. [NCCL, PCIe, NVLink, Infiniband, RDMA都是些啥？](https://www.cnblogs.com/marsggbo/p/16832833.html)

<br><br>

## Video

1. [如何实现集群的通信？](https://www.bilibili.com/video/BV14P4y1S7u4/?spm_id_from=333.999.0.0&vd_source=2ef7e92f2d522c31939f486aea77a19e)

2. [AI集群机器间是怎么通信？通信原语是个什么玩意？](https://www.bilibili.com/video/BV1te4y1e7vz/?spm_id_from=333.788&vd_source=2ef7e92f2d522c31939f486aea77a19e)


