## [Power Your AI Inference with New NVIDIA Triton and NVIDIA TensorRT Features](https://developer.nvidia.com/blog/power-your-ai-inference-with-new-nvidia-triton-and-nvidia-tensorrt-features/)

New features in TensorRT include multi-GPU multi-node inference, performance and hardware optimizations, and more.

* ### Multi-GPU multi-node inference
  * TensorRT can be used to run multi-GPU multi-node inference for large language models (LLMs). It supports GPT-3 175B, 530B, and 6.7B models. These models do not require ONNX conversion; rather, a simple Python API is available to optimize for multi-GPU inference. Now available in private early access. Contact your NVIDIA account team for more details. 
* ### TensorRT 8.6 
  * TensorRT 8.6 is now available in early access and includes the following key features:
    * Performance optimizations for generative AI diffusion and transformer models
    * Hardware compatibility to build and run on different GPU architectures
    * Version compatibility to build and run on different TensorRT versions
    * Optimization levels to trade between build time and inference performance


<br><br>
****
<br><br>

## [NVIDIA TensorRT](https://developer.nvidia.com/blog/sdks-accelerating-industry-5-0-data-pipelines-computational-science-and-more-featured-at-gtc-2023/) (blog time: Mar 22, 2023)

* New features:
  * Performance optimizations for generative AI diffusion and transformer models
  * Enhanced hardware compatibility to build and run on different GPU architectures
  * Version compatibility so that you can build and run on different TensorRT versions from TensorRT 8.6 and later
  * Multi-GPU, multi-node inference for GPT-3 models in early access

<br><br>
****
<br><br>

## 