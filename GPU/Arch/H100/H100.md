## 

> H100 is NVIDIA’s 9th-generation data center GPU designed to deliver an order-of-magnitude performance leap for large-scale AI and HPC over our prior generation NVIDIA A100 Tensor Core GPU. H100 carries over the major design focus of A100 to improve strong scaling for AI and HPC workloads, with substantial improvements in architectural efficiency.
>
> H100 是 NVIDIA 的第 9 代数据中心 GPU，旨在为大规模 AI 和 HPC 提供比上一代 NVIDIA A100 Tensor Core GPU 数量级的性能飞跃。 H100 继承了 A100 的主要设计重点，以提高 AI 和 HPC 工作负载的强大扩展能力，并大幅提高架构效率。
>
> For today’s mainstream AI and HPC models, H100 with InfiniBand interconnect delivers up to 30 times the performance of A100 (see Figure 3).
>
> 对于当今主流的 AI 和 HPC 模型，采用 InfiniBand 互连的 H100 可提供高达 A100 30 倍的性能（见图 3）。




## BLOG

* ### 1. [国内外AI芯片、算力综合对比](https://www.eet-china.com/mp/a229033.html)
  * 很好的一篇blog，需要再deep dive

* ### 2. [NVIDIA H100 PCIe vs. SXM5 Form Factors](https://www.arccompute.io/arc-blog/nvidia-h100-pcie-vs-sxm5-form-factors-which-gpu-is-right-for-your-company)
  * 无论是PCIe板还是SXM板，GPU与GPU之间的互联都是可以通过NVLink进行链接的
  * SXM板可以使用NVSwitch？？？

* ### 3. [NVIDIA H800 AI加速卡，特供中国市场，NVlink带宽缩水，百度、腾讯和阿里巴巴都已采购](https://www.fashaoyou.net/archives/16760)
  * ![Alt text](./images/image.png)
  * SXM版本的NVLink比PCIe版本的NVLink具有更高的带宽？

* ### 4. [NVIDIA DGX versus NVIDIA HGX What is the Difference](https://www.servethehome.com/nvidia-dgx-versus-nvidia-hgx-what-is-the-difference/)

* ### 5. [Announcing NVIDIA DGX GH200: The First 100 Terabyte GPU Memory System](https://developer.nvidia.com/blog/announcing-nvidia-dgx-gh200-first-100-terabyte-gpu-memory-system/)
  * ![Alt text](./images/blog5_image.jpg)
  * Compute baseboards hosting Grace Hopper Superchips are connected to the NVLink Switch System using a custom cable harness for the first layer of NVLink fabric. LinkX cables extend the connectivity in the second layer of NVLink fabric. 
  * **NVIDIA is working to make DGX GH200 available at the end of this year.**

* ### 6. [NVIDIA Reveals DGX GH200 System Architecture](https://www.wheelersnetwork.com/2023/06/nvidia-reveals-dgx-gh200-system.html)
  * The GPU side of all 256 chips is connected using a two-level NVLink network. The first level consists of 96 NVLink switch chips integrated into HGX chassis, whereas 32 NVLink switches reside in switch-system chassis and form the second level. Combined with Grace Hopper's internal coherent interconnect (NVLink-C2C), the NVLink network enables 256 GPUs to access up to 144TB of memory. 